"""
T-Max Ultimate - Self-Correction Agent

è‡ªå·±ä¿®æ­£ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ:
- ç”Ÿæˆã‚³ãƒ¼ãƒ‰ã®è‡ªå‹•æ¤œè¨¼
- ã‚¨ãƒ©ãƒ¼æ¤œå‡ºã¨ãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’
- è‡ªå‹•ä¿®æ­£å€™è£œç”Ÿæˆ
- ä¿®æ­£ã®å†æ¤œè¨¼ãƒ«ãƒ¼ãƒ—ï¼ˆæœ€å¤§3å›ï¼‰
- å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®è“„ç©
"""
import os
import re
import sys
import ast
import json
import hashlib
import subprocess
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from datetime import datetime
from dataclasses import dataclass, asdict

# Add parent directory to path
sys.path.append(str(Path(__file__).parent.parent.parent))

from tmax_work3.blackboard.state_manager import (
    Blackboard,
    AgentType,
    TaskStatus,
    get_blackboard
)

try:
    from anthropic import Anthropic
except ImportError:
    Anthropic = None

try:
    from tmax_work3.agents.evaluator import EvaluatorAgent
except ImportError:
    EvaluatorAgent = None

try:
    from tmax_work3.agents.error_recovery import ErrorRecoveryAgent
except ImportError:
    ErrorRecoveryAgent = None


@dataclass
class ValidationResult:
    """ã‚³ãƒ¼ãƒ‰æ¤œè¨¼çµæœ"""
    is_valid: bool
    syntax_errors: List[Dict]
    test_failures: List[Dict]
    quality_score: float
    error_patterns: List[str]
    timestamp: str


@dataclass
class CorrectionAttempt:
    """ä¿®æ­£è©¦è¡Œã®è¨˜éŒ²"""
    attempt_number: int
    original_code: str
    corrected_code: str
    validation_result: ValidationResult
    correction_strategy: str
    success: bool
    timestamp: str


@dataclass
class LearningEntry:
    """å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚¨ãƒ³ãƒˆãƒª"""
    error_pattern: str
    error_context: str
    successful_fix: Optional[str]
    fix_strategy: str
    success_rate: float
    occurrences: int
    last_seen: str


class SelfCorrectionAgent:
    """
    Self-Correction Agent - è‡ªå·±ä¿®æ­£ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ

    æ©Ÿèƒ½:
    - ç”Ÿæˆã‚³ãƒ¼ãƒ‰ã®æ§‹æ–‡ãƒã‚§ãƒƒã‚¯
    - pytestè‡ªå‹•å®Ÿè¡Œã¨çµæœåˆ†æ
    - ã‚¨ãƒ©ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’
    - Claude APIã§ä¿®æ­£å€™è£œç”Ÿæˆ
    - æœ€å¤§3å›ã®ä¿®æ­£å†æ¤œè¨¼ãƒ«ãƒ¼ãƒ—
    - æˆåŠŸ/å¤±æ•—ãƒ‘ã‚¿ãƒ¼ãƒ³ã®è“„ç©

    çµ±åˆ:
    - Evaluator Agent: ã‚³ãƒ¼ãƒ‰å“è³ªè©•ä¾¡
    - Error Recovery Agent: ã‚¨ãƒ©ãƒ¼åˆ†æã¨ä¿®æ­£
    """

    MAX_CORRECTION_ATTEMPTS = 3

    def __init__(self, repository_path: str):
        self.repo_path = Path(repository_path)
        self.blackboard = get_blackboard()

        # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹
        self.learning_data_path = self.repo_path / "tmax_work3" / "data" / "self_correction_learning.json"
        self.learning_data_path.parent.mkdir(parents=True, exist_ok=True)

        # ä¿®æ­£å±¥æ­´ãƒ‘ã‚¹
        self.correction_history_path = self.repo_path / "tmax_work3" / "data" / "correction_history"
        self.correction_history_path.mkdir(parents=True, exist_ok=True)

        # Claude APIåˆæœŸåŒ–
        self.claude_client = None
        if Anthropic and os.getenv("ANTHROPIC_API_KEY"):
            self.claude_client = Anthropic(api_key=os.getenv("ANTHROPIC_API_KEY"))

        # Evaluator AgentåˆæœŸåŒ–
        self.evaluator = None
        if EvaluatorAgent:
            try:
                self.evaluator = EvaluatorAgent(str(self.repo_path))
            except:
                pass

        # Error Recovery AgentåˆæœŸåŒ–
        self.error_recovery = None
        if ErrorRecoveryAgent:
            try:
                self.error_recovery = ErrorRecoveryAgent(str(self.repo_path))
            except:
                pass

        # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆç™»éŒ²
        try:
            self.blackboard.register_agent(
                AgentType.QA,  # Self-correctionã¯QAã®ä¸€ç¨®ã¨ã—ã¦æ‰±ã†
                worktree="main"
            )
        except:
            pass

        # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰
        self.learning_data = self._load_learning_data()

        self.blackboard.log(
            "ğŸ”„ Self-Correction Agent initialized - Auto-validation and learning enabled",
            level="INFO",
            agent=AgentType.QA
        )

    def _load_learning_data(self) -> Dict[str, LearningEntry]:
        """å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€"""
        if self.learning_data_path.exists():
            try:
                data = json.loads(self.learning_data_path.read_text())
                return {
                    k: LearningEntry(**v) for k, v in data.items()
                }
            except Exception as e:
                self.blackboard.log(
                    f"âš ï¸ Failed to load learning data: {e}",
                    level="WARNING",
                    agent=AgentType.QA
                )

        return {}

    def _save_learning_data(self):
        """å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜"""
        try:
            data = {
                k: asdict(v) for k, v in self.learning_data.items()
            }
            self.learning_data_path.write_text(json.dumps(data, indent=2))
        except Exception as e:
            self.blackboard.log(
                f"âš ï¸ Failed to save learning data: {e}",
                level="WARNING",
                agent=AgentType.QA
            )

    def validate_code(self, code: str, file_path: Optional[str] = None) -> ValidationResult:
        """
        ã‚³ãƒ¼ãƒ‰ã‚’æ¤œè¨¼

        Args:
            code: æ¤œè¨¼ã™ã‚‹ã‚³ãƒ¼ãƒ‰
            file_path: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆpytestå®Ÿè¡Œç”¨ï¼‰

        Returns:
            ValidationResult
        """
        self.blackboard.log(
            "ğŸ” Validating code...",
            level="INFO",
            agent=AgentType.QA
        )

        syntax_errors = []
        test_failures = []
        error_patterns = []
        quality_score = 1.0

        # 1. æ§‹æ–‡ãƒã‚§ãƒƒã‚¯
        try:
            ast.parse(code)
        except SyntaxError as e:
            syntax_errors.append({
                "type": "SyntaxError",
                "message": str(e),
                "line": e.lineno,
                "offset": e.offset
            })
            quality_score -= 0.5

            # ã‚¨ãƒ©ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’
            error_pattern = self._extract_error_pattern(str(e))
            error_patterns.append(error_pattern)

        # 2. é™çš„è§£æï¼ˆç°¡æ˜“ç‰ˆï¼‰
        static_issues = self._static_analysis(code)
        if static_issues:
            quality_score -= 0.1 * len(static_issues)
            for issue in static_issues:
                error_patterns.append(issue["pattern"])

        # 3. pytestå®Ÿè¡Œï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆï¼‰
        if file_path and Path(file_path).exists():
            test_results = self._run_pytest(file_path)
            if test_results["failed"] > 0:
                test_failures = test_results["failures"]
                quality_score -= 0.3
                for failure in test_failures:
                    pattern = self._extract_error_pattern(failure["message"])
                    error_patterns.append(pattern)

        # 4. Evaluatorçµ±åˆï¼ˆã‚³ãƒ¼ãƒ‰å“è³ªè©•ä¾¡ï¼‰
        if self.evaluator and file_path:
            try:
                eval_score = self.evaluator._check_code_quality(Path(file_path).parent)
                quality_score = (quality_score + eval_score) / 2
            except:
                pass

        is_valid = len(syntax_errors) == 0 and len(test_failures) == 0

        result = ValidationResult(
            is_valid=is_valid,
            syntax_errors=syntax_errors,
            test_failures=test_failures,
            quality_score=max(0.0, min(1.0, quality_score)),
            error_patterns=error_patterns,
            timestamp=datetime.now().isoformat()
        )

        log_level = "SUCCESS" if is_valid else "WARNING"
        self.blackboard.log(
            f"âœ… Validation complete: Valid={is_valid}, Quality={quality_score:.2f}",
            level=log_level,
            agent=AgentType.QA
        )

        return result

    def _static_analysis(self, code: str) -> List[Dict]:
        """
        é™çš„è§£æï¼ˆç°¡æ˜“ç‰ˆï¼‰

        ãƒã‚§ãƒƒã‚¯é …ç›®:
        - æœªä½¿ç”¨ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
        - æœªå®šç¾©å¤‰æ•°ï¼ˆåŸºæœ¬çš„ãªã‚‚ã®ï¼‰
        - ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è¦ç´„é•åï¼ˆåŸºæœ¬çš„ãªã‚‚ã®ï¼‰

        Returns:
            å•é¡Œãƒªã‚¹ãƒˆ
        """
        issues = []

        try:
            tree = ast.parse(code)

            # æœªä½¿ç”¨ã‚¤ãƒ³ãƒãƒ¼ãƒˆã®ç°¡æ˜“æ¤œå‡º
            imports = []
            for node in ast.walk(tree):
                if isinstance(node, ast.Import):
                    for alias in node.names:
                        imports.append(alias.name)
                elif isinstance(node, ast.ImportFrom):
                    for alias in node.names:
                        imports.append(alias.name)

            # ã‚³ãƒ¼ãƒ‰ä¸­ã§ã®ä½¿ç”¨ãƒã‚§ãƒƒã‚¯ï¼ˆç°¡æ˜“ç‰ˆï¼‰
            code_lower = code.lower()
            for imp in imports:
                if imp.lower() not in code_lower.replace(f"import {imp.lower()}", ""):
                    issues.append({
                        "type": "unused_import",
                        "pattern": f"unused_import:{imp}",
                        "message": f"Unused import: {imp}"
                    })

        except:
            pass

        return issues

    def _run_pytest(self, file_path: str) -> Dict:
        """
        pytestã‚’å®Ÿè¡Œ

        Returns:
            {
                "passed": 10,
                "failed": 2,
                "failures": [...]
            }
        """
        try:
            result = subprocess.run(
                ["pytest", file_path, "-v", "--tb=short", "--json-report", "--json-report-file=test_report.json"],
                cwd=self.repo_path,
                capture_output=True,
                text=True,
                timeout=60
            )

            # JSONãƒ¬ãƒãƒ¼ãƒˆèª­ã¿è¾¼ã¿
            report_file = self.repo_path / "test_report.json"
            if report_file.exists():
                report = json.loads(report_file.read_text())

                failures = []
                for test in report.get("tests", []):
                    if test.get("outcome") == "failed":
                        failures.append({
                            "test_name": test["nodeid"],
                            "message": test.get("call", {}).get("longrepr", "")
                        })

                return {
                    "passed": report["summary"].get("passed", 0),
                    "failed": report["summary"].get("failed", 0),
                    "failures": failures
                }

        except Exception as e:
            self.blackboard.log(
                f"âš ï¸ pytest execution failed: {e}",
                level="WARNING",
                agent=AgentType.QA
            )

        return {"passed": 0, "failed": 0, "failures": []}

    def _extract_error_pattern(self, error_message: str) -> str:
        """
        ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŠ½å‡º

        ä¾‹:
        - "NameError: name 'foo' is not defined" -> "name_not_defined"
        - "SyntaxError: invalid syntax" -> "invalid_syntax"
        """
        # ä¸€èˆ¬çš„ãªã‚¨ãƒ©ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒãƒƒãƒ
        patterns = {
            r"name '.*' is not defined": "name_not_defined",
            r"invalid syntax": "invalid_syntax",
            r"unexpected indent": "unexpected_indent",
            r"unresolved reference": "unresolved_reference",
            r"module '.*' has no attribute": "no_attribute",
            r"cannot import name": "import_error",
            r"division by zero": "division_by_zero",
            r"index out of range": "index_out_of_range",
            r"key error": "key_error",
            r"type error": "type_error",
            r"value error": "value_error",
            r"assertion.*failed": "assertion_failed",
        }

        error_lower = error_message.lower()
        for pattern, name in patterns.items():
            if re.search(pattern, error_lower):
                return name

        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ãƒãƒƒã‚·ãƒ¥åŒ–
        return f"error_{hashlib.md5(error_message.encode()).hexdigest()[:8]}"

    def generate_correction(self, code: str, validation_result: ValidationResult, context: Optional[str] = None) -> Tuple[bool, str]:
        """
        ä¿®æ­£å€™è£œã‚’ç”Ÿæˆ

        Args:
            code: å…ƒã®ã‚³ãƒ¼ãƒ‰
            validation_result: æ¤œè¨¼çµæœ
            context: è¿½åŠ ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ

        Returns:
            (success, corrected_code)
        """
        self.blackboard.log(
            "ğŸ› ï¸ Generating correction...",
            level="INFO",
            agent=AgentType.QA
        )

        # Claude APIãŒä½¿ç”¨å¯èƒ½ãªå ´åˆ
        if self.claude_client:
            return self._generate_correction_with_claude(code, validation_result, context)

        # Error Recovery Agentã¨ã®çµ±åˆ
        if self.error_recovery and validation_result.error_patterns:
            try:
                error_log = "\n".join([
                    f"{e['type']}: {e['message']}" for e in validation_result.syntax_errors
                ])
                analysis = self.error_recovery.analyze_error(error_log, context)
                success, fix_code = self.error_recovery.generate_fix(analysis)
                if success:
                    return True, fix_code
            except:
                pass

        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ™ãƒ¼ã‚¹ã®ä¿®æ­£
        return self._pattern_based_correction(code, validation_result)

    def _generate_correction_with_claude(self, code: str, validation_result: ValidationResult, context: Optional[str]) -> Tuple[bool, str]:
        """Claude APIã§ä¿®æ­£å€™è£œã‚’ç”Ÿæˆ"""
        # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰é¡ä¼¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œç´¢
        similar_fixes = self._find_similar_patterns(validation_result.error_patterns)

        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
        prompt = self._build_correction_prompt(code, validation_result, similar_fixes, context)

        try:
            message = self.claude_client.messages.create(
                model="claude-3-5-sonnet-20241022",
                max_tokens=4000,
                messages=[{"role": "user", "content": prompt}]
            )

            response_text = message.content[0].text

            # ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚’æŠ½å‡º
            code_match = re.search(r'```python\n(.*?)\n```', response_text, re.DOTALL)
            if code_match:
                corrected_code = code_match.group(1)

                self.blackboard.log(
                    "âœ… Correction generated with Claude API",
                    level="SUCCESS",
                    agent=AgentType.QA
                )

                return True, corrected_code

        except Exception as e:
            self.blackboard.log(
                f"âš ï¸ Claude correction generation failed: {e}",
                level="WARNING",
                agent=AgentType.QA
            )

        return False, code

    def _build_correction_prompt(self, code: str, validation_result: ValidationResult, similar_fixes: List[LearningEntry], context: Optional[str]) -> str:
        """ä¿®æ­£ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰"""
        prompt_parts = [
            "# Code Correction Request",
            "",
            "## Original Code",
            "```python",
            code,
            "```",
            "",
            "## Validation Errors",
        ]

        # æ§‹æ–‡ã‚¨ãƒ©ãƒ¼
        if validation_result.syntax_errors:
            prompt_parts.append("### Syntax Errors:")
            for error in validation_result.syntax_errors:
                prompt_parts.append(f"- Line {error['line']}: {error['message']}")

        # ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼
        if validation_result.test_failures:
            prompt_parts.append("\n### Test Failures:")
            for failure in validation_result.test_failures:
                prompt_parts.append(f"- {failure['test_name']}: {failure['message'][:200]}")

        # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰é¡ä¼¼ä¿®æ­£
        if similar_fixes:
            prompt_parts.append("\n## Similar Successful Fixes (Learning Data):")
            for i, fix in enumerate(similar_fixes[:3], 1):
                prompt_parts.append(f"\n### Fix {i} (Success Rate: {fix.success_rate:.1%})")
                prompt_parts.append(f"Error Pattern: {fix.error_pattern}")
                prompt_parts.append(f"Strategy: {fix.fix_strategy}")
                if fix.successful_fix:
                    prompt_parts.append(f"Fix Applied:\n{fix.successful_fix[:300]}")

        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
        if context:
            prompt_parts.append(f"\n## Additional Context\n{context}")

        prompt_parts.extend([
            "",
            "## Task",
            "Please provide a corrected version of the code that:",
            "1. Fixes all syntax errors",
            "2. Passes all tests",
            "3. Maintains the original functionality",
            "4. Follows Python best practices",
            "",
            "Return ONLY the corrected Python code in a ```python code block, with no additional explanation.",
        ])

        return "\n".join(prompt_parts)

    def _find_similar_patterns(self, error_patterns: List[str]) -> List[LearningEntry]:
        """å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰é¡ä¼¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œç´¢"""
        similar = []

        for pattern in error_patterns:
            if pattern in self.learning_data:
                similar.append(self.learning_data[pattern])

        # æˆåŠŸç‡ã§ã‚½ãƒ¼ãƒˆ
        similar.sort(key=lambda x: x.success_rate, reverse=True)

        return similar

    def _pattern_based_correction(self, code: str, validation_result: ValidationResult) -> Tuple[bool, str]:
        """ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ™ãƒ¼ã‚¹ã®ç°¡æ˜“ä¿®æ­£"""
        corrected = code

        # ç°¡æ˜“ä¿®æ­£ãƒ«ãƒ¼ãƒ«
        for error in validation_result.syntax_errors:
            if "unexpected indent" in error["message"]:
                # ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆä¿®æ­£ï¼ˆç°¡æ˜“ç‰ˆï¼‰
                lines = corrected.split("\n")
                if 0 <= error["line"] - 1 < len(lines):
                    lines[error["line"] - 1] = lines[error["line"] - 1].lstrip()
                corrected = "\n".join(lines)

        return True, corrected

    def correct_with_retry(self, code: str, file_path: Optional[str] = None, context: Optional[str] = None) -> Dict:
        """
        æœ€å¤§3å›ã®å†æ¤œè¨¼ãƒ«ãƒ¼ãƒ—ã§ä¿®æ­£

        Returns:
            {
                "success": bool,
                "final_code": str,
                "attempts": List[CorrectionAttempt],
                "learning_updated": bool
            }
        """
        self.blackboard.log(
            f"ğŸ”„ Starting correction cycle (max {self.MAX_CORRECTION_ATTEMPTS} attempts)...",
            level="INFO",
            agent=AgentType.QA
        )

        attempts = []
        current_code = code
        final_success = False

        for attempt_num in range(1, self.MAX_CORRECTION_ATTEMPTS + 1):
            self.blackboard.log(
                f"ğŸ“ Attempt {attempt_num}/{self.MAX_CORRECTION_ATTEMPTS}",
                level="INFO",
                agent=AgentType.QA
            )

            # æ¤œè¨¼
            validation = self.validate_code(current_code, file_path)

            if validation.is_valid:
                self.blackboard.log(
                    f"âœ… Code valid after {attempt_num} attempt(s)!",
                    level="SUCCESS",
                    agent=AgentType.QA
                )
                final_success = True

                # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿æ›´æ–°ï¼ˆæˆåŠŸï¼‰
                self._update_learning_data(validation.error_patterns, current_code, "success", True)

                attempts.append(CorrectionAttempt(
                    attempt_number=attempt_num,
                    original_code=code,
                    corrected_code=current_code,
                    validation_result=validation,
                    correction_strategy="validation_passed",
                    success=True,
                    timestamp=datetime.now().isoformat()
                ))

                break

            # ä¿®æ­£ç”Ÿæˆ
            success, corrected_code = self.generate_correction(current_code, validation, context)

            attempts.append(CorrectionAttempt(
                attempt_number=attempt_num,
                original_code=current_code,
                corrected_code=corrected_code,
                validation_result=validation,
                correction_strategy="claude_api" if self.claude_client else "pattern_based",
                success=False,
                timestamp=datetime.now().isoformat()
            ))

            if not success:
                self.blackboard.log(
                    f"âš ï¸ Correction generation failed at attempt {attempt_num}",
                    level="WARNING",
                    agent=AgentType.QA
                )
                # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿æ›´æ–°ï¼ˆå¤±æ•—ï¼‰
                self._update_learning_data(validation.error_patterns, None, "generation_failed", False)
                break

            current_code = corrected_code

        # æœ€çµ‚æ¤œè¨¼
        if not final_success and attempts:
            self.blackboard.log(
                f"âŒ Failed to correct code after {len(attempts)} attempts",
                level="ERROR",
                agent=AgentType.QA
            )
            # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿æ›´æ–°ï¼ˆå¤±æ•—ï¼‰
            last_validation = attempts[-1].validation_result
            self._update_learning_data(last_validation.error_patterns, None, "max_retries_exceeded", False)

        # ä¿®æ­£å±¥æ­´ã‚’ä¿å­˜
        self._save_correction_history(attempts)

        result = {
            "success": final_success,
            "final_code": current_code,
            "attempts": [asdict(a) for a in attempts],
            "learning_updated": True,
            "timestamp": datetime.now().isoformat()
        }

        return result

    def _update_learning_data(self, error_patterns: List[str], successful_fix: Optional[str], strategy: str, success: bool):
        """å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°"""
        for pattern in error_patterns:
            if pattern not in self.learning_data:
                self.learning_data[pattern] = LearningEntry(
                    error_pattern=pattern,
                    error_context="",
                    successful_fix=None,
                    fix_strategy="",
                    success_rate=0.0,
                    occurrences=0,
                    last_seen=datetime.now().isoformat()
                )

            entry = self.learning_data[pattern]
            entry.occurrences += 1
            entry.last_seen = datetime.now().isoformat()

            if success and successful_fix:
                entry.successful_fix = successful_fix[:1000]  # æœ€å¤§1000æ–‡å­—
                entry.fix_strategy = strategy

                # æˆåŠŸç‡æ›´æ–°ï¼ˆç§»å‹•å¹³å‡ï¼‰
                entry.success_rate = (entry.success_rate * (entry.occurrences - 1) + 1.0) / entry.occurrences
            else:
                # å¤±æ•—æ™‚ã¯æˆåŠŸç‡ã‚’ä¸‹ã’ã‚‹
                entry.success_rate = (entry.success_rate * (entry.occurrences - 1)) / entry.occurrences

        self._save_learning_data()

    def _save_correction_history(self, attempts: List[CorrectionAttempt]):
        """ä¿®æ­£å±¥æ­´ã‚’ä¿å­˜"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        history_file = self.correction_history_path / f"correction_{timestamp}.json"

        data = [asdict(a) for a in attempts]
        history_file.write_text(json.dumps(data, indent=2))

        self.blackboard.log(
            f"ğŸ’¾ Correction history saved: {history_file}",
            level="INFO",
            agent=AgentType.QA
        )

    def analyze_learning_data(self) -> Dict:
        """
        å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æ

        Returns:
            çµ±è¨ˆæƒ…å ±
        """
        total_patterns = len(self.learning_data)
        successful_patterns = sum(1 for e in self.learning_data.values() if e.success_rate > 0.5)
        avg_success_rate = sum(e.success_rate for e in self.learning_data.values()) / total_patterns if total_patterns > 0 else 0.0

        top_patterns = sorted(
            self.learning_data.values(),
            key=lambda x: x.occurrences,
            reverse=True
        )[:10]

        return {
            "total_patterns": total_patterns,
            "successful_patterns": successful_patterns,
            "average_success_rate": round(avg_success_rate, 4),
            "top_patterns": [
                {
                    "pattern": p.error_pattern,
                    "occurrences": p.occurrences,
                    "success_rate": p.success_rate,
                    "strategy": p.fix_strategy
                }
                for p in top_patterns
            ],
            "timestamp": datetime.now().isoformat()
        }


# ãƒ†ã‚¹ãƒˆç”¨ã‚³ãƒ¼ãƒ‰
if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="T-Max Self-Correction Agent")
    parser.add_argument("--test", action="store_true", help="Run test")
    parser.add_argument("--code", help="Code to validate and correct")
    parser.add_argument("--file", help="File path to validate and correct")
    parser.add_argument("--analyze", action="store_true", help="Analyze learning data")
    args = parser.parse_args()

    agent = SelfCorrectionAgent(".")

    if args.analyze:
        print("ğŸ“Š Analyzing learning data...")
        analysis = agent.analyze_learning_data()
        print(json.dumps(analysis, indent=2))

    elif args.test:
        print("ğŸ§ª Testing Self-Correction Agent...")

        # ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰ï¼ˆæ„å›³çš„ãªã‚¨ãƒ©ãƒ¼ï¼‰
        broken_code = """
def calculate_sum(a, b):
    result = a + b
      return result  # ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆã‚¨ãƒ©ãƒ¼

def divide(x, y):
    return x / y  # division by zeroã®å¯èƒ½æ€§
"""

        print("\nğŸ“ Original (broken) code:")
        print(broken_code)

        # ä¿®æ­£ã‚µã‚¤ã‚¯ãƒ«å®Ÿè¡Œ
        result = agent.correct_with_retry(broken_code)

        print(f"\nâœ… Correction Result:")
        print(f"Success: {result['success']}")
        print(f"Attempts: {len(result['attempts'])}")

        if result['success']:
            print(f"\nğŸ‰ Final corrected code:")
            print(result['final_code'])

        # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿åˆ†æ
        print("\nğŸ“Š Learning Data Analysis:")
        analysis = agent.analyze_learning_data()
        print(json.dumps(analysis, indent=2))

    elif args.code:
        print("ğŸ” Validating and correcting code...")
        result = agent.correct_with_retry(args.code)
        print(json.dumps(result, indent=2))

    elif args.file:
        print(f"ğŸ” Validating and correcting file: {args.file}")
        code = Path(args.file).read_text()
        result = agent.correct_with_retry(code, args.file)
        print(json.dumps(result, indent=2))

    else:
        print("Usage: python self_correction.py [--test|--analyze|--code CODE|--file FILE]")
