"""
OCR Endpoint

Kindleç”»åƒã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¨OCRå‡¦ç†ã‚’è¡Œã†ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
Phase 1-3 MVP Implementation + Rate Limiting (Phase 1-8)
"""
from fastapi import APIRouter, UploadFile, File, Depends, HTTPException, status, Request
from sqlalchemy.orm import Session
from typing import Optional
import pytesseract
from PIL import Image
import io
import logging
import uuid

from app.core.database import get_db
from app.core.security import get_current_user_or_default
from app.models import Job, OCRResult, User
from app.schemas.ocr import OCRUploadResponse, JobResponse
from app.services.rate_limiter import limiter, RateLimitConfig

# ãƒ­ã‚¬ãƒ¼è¨­å®š
logger = logging.getLogger(__name__)

# ãƒ«ãƒ¼ã‚¿ãƒ¼è¨­å®š
router = APIRouter()

# è¨±å¯ã™ã‚‹ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼
ALLOWED_EXTENSIONS = {".png", ".jpg", ".jpeg"}
MAX_FILE_SIZE = 10 * 1024 * 1024  # 10MB


def validate_image_file(file: UploadFile) -> None:
    """
    ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³

    Args:
        file: ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«

    Raises:
        HTTPException: ãƒ•ã‚¡ã‚¤ãƒ«ãŒç„¡åŠ¹ãªå ´åˆ
    """
    # ãƒ•ã‚¡ã‚¤ãƒ«åãƒã‚§ãƒƒã‚¯
    if not file.filename:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="ãƒ•ã‚¡ã‚¤ãƒ«åãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"
        )

    # æ‹¡å¼µå­ãƒã‚§ãƒƒã‚¯
    file_ext = "." + file.filename.split(".")[-1].lower()
    if file_ext not in ALLOWED_EXTENSIONS:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"è¨±å¯ã•ã‚Œã¦ã„ãªã„ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã§ã™ã€‚å¯¾å¿œå½¢å¼: {', '.join(ALLOWED_EXTENSIONS)}"
        )


def extract_text_from_image(image_data: bytes) -> tuple[str, float]:
    """
    é«˜ç²¾åº¦OCRå‡¦ç†ï¼ˆç”»åƒå‰å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³é©ç”¨ + ãƒ˜ãƒƒãƒ€ãƒ¼/ãƒ•ãƒƒã‚¿ãƒ¼é™¤å»ï¼‰

    å‡¦ç†ãƒ•ãƒ­ãƒ¼:
    1. ç”»åƒå‰å‡¦ç†ï¼ˆãƒã‚¤ã‚ºé™¤å»ã€ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆå¼·èª¿ã€äºŒå€¤åŒ–ï¼‰
    2. ãƒ˜ãƒƒãƒ€ãƒ¼/ãƒ•ãƒƒã‚¿ãƒ¼é ˜åŸŸã®é™¤å»ï¼ˆä¸Šä¸‹10%ï¼‰
    3. Tesseract OCRå®Ÿè¡Œï¼ˆæ—¥æœ¬èª+è‹±èªã€æœ€é©åŒ–è¨­å®šï¼‰
    4. ãƒ†ã‚­ã‚¹ãƒˆã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆãƒšãƒ¼ã‚¸ç•ªå·ãªã©ã®é™¤å»ï¼‰
    5. ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢è¨ˆç®—

    Args:
        image_data: ç”»åƒãƒ‡ãƒ¼ã‚¿ (bytes)

    Returns:
        tuple[str, float]: (æŠ½å‡ºã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ, ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ 0.0-1.0)

    Raises:
        HTTPException: OCRå‡¦ç†ã«å¤±æ•—ã—ãŸå ´åˆ
    """
    try:
        # æ–°ã—ã„é«˜ç²¾åº¦OCRã‚µãƒ¼ãƒ“ã‚¹ã‚’ä½¿ç”¨ï¼ˆãƒ˜ãƒƒãƒ€ãƒ¼/ãƒ•ãƒƒã‚¿ãƒ¼é™¤å»ä»˜ãï¼‰
        from app.services.ocr_service import extract_text_from_image_bytes

        text, confidence = extract_text_from_image_bytes(image_data)

        # ãƒ†ã‚­ã‚¹ãƒˆã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆãƒšãƒ¼ã‚¸ç•ªå·ãªã©ã®é™¤å»ï¼‰
        text = _clean_ocr_text(text)

        logger.info(f"âœ… Enhanced OCR complete: {len(text)} chars, {confidence:.2%} confidence")

        return text, confidence

    except Exception as e:
        logger.error(f"âŒ Enhanced OCRå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)

        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å¾“æ¥ã®OCRå‡¦ç†
        logger.warning("âš ï¸ Falling back to legacy OCR processing")
        try:
            # PIL Imageã«å¤‰æ›
            image = Image.open(io.BytesIO(image_data))

            # Tesseract OCRå®Ÿè¡Œï¼ˆæ—¥æœ¬èª+è‹±èªï¼‰
            custom_config = r'--oem 3 --psm 6'  # LSTM OCRã‚¨ãƒ³ã‚¸ãƒ³ + å˜ä¸€ãƒ–ãƒ­ãƒƒã‚¯
            text = pytesseract.image_to_string(
                image,
                lang='jpn+eng',
                config=custom_config
            )

            # ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ã‚’å–å¾—
            data = pytesseract.image_to_data(
                image,
                lang='jpn+eng',
                config=custom_config,
                output_type=pytesseract.Output.DICT
            )

            # ä¿¡é ¼åº¦ã®å¹³å‡ã‚’è¨ˆç®—ï¼ˆ-1ã¯ç„¡åŠ¹ãªå€¤ãªã®ã§é™¤å¤–ï¼‰
            confidences = [float(conf) for conf in data['conf'] if conf != '-1' and int(conf) >= 0]
            avg_confidence = sum(confidences) / len(confidences) / 100.0 if confidences else 0.0

            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã§ã‚‚ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°é©ç”¨
            text = _clean_ocr_text(text)

            return text.strip(), avg_confidence

        except Exception as fallback_error:
            logger.error(f"âŒ Fallback OCR also failed: {fallback_error}", exc_info=True)
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail=f"OCRå‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}"
            )


def _clean_ocr_text(text: str) -> str:
    """
    OCRæŠ½å‡ºãƒ†ã‚­ã‚¹ãƒˆã®ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆãƒšãƒ¼ã‚¸ç•ªå·ãªã©ã®é™¤å»ï¼‰

    é™¤å»å¯¾è±¡:
    - ã€ŒPage Xã€å½¢å¼ã®ãƒšãƒ¼ã‚¸ç•ªå·
    - ã€Œãƒšãƒ¼ã‚¸ Xã€å½¢å¼ã®ãƒšãƒ¼ã‚¸ç•ªå·
    - æ•°å­—ã®ã¿ã®çŸ­ã„è¡Œï¼ˆãƒšãƒ¼ã‚¸ç•ªå·ã®å¯èƒ½æ€§ï¼‰
    - éåº¦ãªç©ºç™½è¡Œ

    Args:
        text: OCRæŠ½å‡ºã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ

    Returns:
        str: ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ
    """
    import re

    if not text:
        return ""

    lines = text.split('\n')
    cleaned_lines = []

    for line in lines:
        line = line.strip()

        if not line:
            continue

        # ã€ŒPage Xã€å½¢å¼ã®ãƒšãƒ¼ã‚¸ç•ªå·ã‚’é™¤å»
        if re.match(r'^Page\s+\d+$', line, re.IGNORECASE):
            continue

        # ã€Œãƒšãƒ¼ã‚¸ Xã€å½¢å¼ã®ãƒšãƒ¼ã‚¸ç•ªå·ã‚’é™¤å»
        if re.match(r'^ãƒšãƒ¼ã‚¸\s*\d+$', line):
            continue

        # æ•°å­—ã®ã¿ã®çŸ­ã„è¡Œã‚’é™¤å»ï¼ˆãƒšãƒ¼ã‚¸ç•ªå·ã®å¯èƒ½æ€§ï¼‰
        if re.match(r'^\d+$', line) and len(line) <= 4:
            continue

        # çŸ­ã™ãã‚‹è¡Œï¼ˆãƒã‚¤ã‚ºï¼‰ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼ˆæ—¥æœ¬èªæ–‡å­—ã¯ä¾‹å¤–ï¼‰
        if len(line) < 2 and not any('\u3040' <= c <= '\u309F' or '\u30A0' <= c <= '\u30FF' or '\u4E00' <= c <= '\u9FFF' for c in line):
            continue

        cleaned_lines.append(line)

    cleaned_text = '\n'.join(cleaned_lines)

    # 3è¡Œä»¥ä¸Šã®é€£ç¶šæ”¹è¡Œã‚’2è¡Œã«åœ§ç¸®
    cleaned_text = re.sub(r'\n{3,}', '\n\n', cleaned_text)

    return cleaned_text.strip()


@router.post("/upload", response_model=OCRUploadResponse, status_code=status.HTTP_201_CREATED)
@limiter.limit(RateLimitConfig.OCR_UPLOAD)
async def upload_and_ocr(
    request: Request,
    file: UploadFile = File(..., description="OCRå‡¦ç†ã™ã‚‹ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«"),
    book_title: str = "Untitled",
    page_num: int = 1,
    current_user: User = Depends(get_current_user_or_default),
    db: Session = Depends(get_db)
) -> OCRUploadResponse:
    """
    ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦OCRå‡¦ç†ã‚’å®Ÿè¡Œ

    Args:
        file: ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒãƒ•ã‚¡ã‚¤ãƒ« (.png, .jpg, .jpeg)
        book_title: æ›¸ç±ã‚¿ã‚¤ãƒˆãƒ« (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: "Untitled")
        page_num: ãƒšãƒ¼ã‚¸ç•ªå· (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1)
        db: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚»ãƒƒã‚·ãƒ§ãƒ³

    Returns:
        OCRUploadResponse: OCRçµæœï¼ˆjob_id, book_title, page_num, text, confidenceï¼‰

    Raises:
        HTTPException: ãƒ•ã‚¡ã‚¤ãƒ«ãŒç„¡åŠ¹ã€OCRå‡¦ç†å¤±æ•—ã€DBä¿å­˜å¤±æ•—æ™‚
    """
    logger.info(f"ğŸ“¤ OCRã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰é–‹å§‹: {file.filename}, æ›¸ç±={book_title}, ãƒšãƒ¼ã‚¸={page_num}")

    # ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
    validate_image_file(file)

    try:
        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
        image_data = await file.read()

        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
        if len(image_data) > MAX_FILE_SIZE:
            raise HTTPException(
                status_code=status.HTTP_413_REQUEST_ENTITY_TOO_LARGE,
                detail=f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒå¤§ãã™ãã¾ã™ï¼ˆä¸Šé™: {MAX_FILE_SIZE / 1024 / 1024}MBï¼‰"
            )

        # Jobä½œæˆ
        job_id = str(uuid.uuid4())
        job = Job(
            id=job_id,
            user_id=current_user.id,  # èªè¨¼ã•ã‚ŒãŸãƒ¦ãƒ¼ã‚¶ãƒ¼ID
            type="ocr",
            status="processing",
            progress=0
        )
        db.add(job)
        db.flush()  # IDã‚’å–å¾—ã™ã‚‹ãŸã‚ã«flush

        logger.info(f"âœ… Jobä½œæˆå®Œäº†: job_id={job_id}")

        # OCRå‡¦ç†å®Ÿè¡Œ
        logger.info("ğŸ” OCRå‡¦ç†é–‹å§‹...")
        extracted_text, confidence = extract_text_from_image(image_data)
        logger.info(f"âœ… OCRå‡¦ç†å®Œäº†: ãƒ†ã‚­ã‚¹ãƒˆé•·={len(extracted_text)}, ä¿¡é ¼åº¦={confidence:.2f}")

        # OCRResultä¿å­˜
        ocr_result = OCRResult(
            job_id=job_id,
            book_title=book_title,
            page_num=page_num,
            text=extracted_text,
            confidence=confidence,
            image_blob=image_data  # ç”»åƒã‚’BYTEAã¨ã—ã¦ä¿å­˜
        )
        db.add(ocr_result)

        # Jobã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æ›´æ–°
        job.status = "completed"
        job.progress = 100

        # ã‚³ãƒŸãƒƒãƒˆ
        db.commit()
        db.refresh(ocr_result)

        logger.info(f"âœ… OCRçµæœä¿å­˜å®Œäº†: ocr_result_id={ocr_result.id}")

        return OCRUploadResponse(
            job_id=job_id,
            book_title=book_title,
            page_num=page_num,
            text=extracted_text,
            confidence=confidence
        )

    except HTTPException:
        # HTTPExceptionã¯ãã®ã¾ã¾å†é€å‡º
        db.rollback()
        raise

    except Exception as e:
        db.rollback()
        logger.error(f"âŒ OCRå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"OCRå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
        )


@router.get("/jobs/{job_id}", response_model=JobResponse)
@limiter.limit(RateLimitConfig.STANDARD_API)
async def get_job_status(
    request: Request,
    job_id: str,
    current_user: User = Depends(get_current_user_or_default),
    db: Session = Depends(get_db)
) -> JobResponse:
    """
    ã‚¸ãƒ§ãƒ–ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’å–å¾—

    Args:
        job_id: ã‚¸ãƒ§ãƒ–ID (UUID)
        db: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚»ãƒƒã‚·ãƒ§ãƒ³

    Returns:
        JobResponse: ã‚¸ãƒ§ãƒ–æƒ…å ±

    Raises:
        HTTPException: ã‚¸ãƒ§ãƒ–ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆ
    """
    job = db.query(Job).filter(Job.id == job_id, Job.user_id == current_user.id).first()

    if not job:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"ã‚¸ãƒ§ãƒ–ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {job_id}"
        )

    return JobResponse(
        id=job.id,
        user_id=job.user_id,
        type=job.type,
        status=job.status,
        progress=job.progress,
        created_at=job.created_at
    )
